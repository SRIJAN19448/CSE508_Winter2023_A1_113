{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\srija\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import pickle\n",
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def helper(inv_idx_freq, inv_idx_postings, set_of_tokens, docID):\n",
    "    for j in set_of_tokens:\n",
    "        inv_idx_postings[j].append(docID)\n",
    "        inv_idx_freq[j] = inv_idx_freq[j] + 1\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1_and_t2(posting1, posting2):\n",
    "  \n",
    "  # if any of the postings is empty then their intersection will also be an empty list\n",
    "  if len(posting1) == 0 or len(posting2) == 0:\n",
    "    return []\n",
    "\n",
    "  ptr1 = 0 #pointer that iterates over posting 1\n",
    "  ptr2 = 0 #pointer that iterates over posting 2\n",
    "\n",
    "  comparisons = 0 #intialize number of comparison as 0\n",
    "  ans = []\n",
    "\n",
    "\n",
    "  while ptr1 < len(posting1) and ptr2 < len(posting2):\n",
    "    comparisons += 1 \n",
    "    if posting1[ptr1] ==  posting2[ptr2]: # this means that both the docs contains the word.\n",
    "      ans.append(posting1[ptr1])\n",
    "      ptr1 = ptr1 + 1\n",
    "      ptr2 = ptr2 + 1\n",
    "\n",
    "    elif posting1[ptr1] <  posting2[ptr2]:\n",
    "      ptr1 = ptr1 + 1\n",
    "    \n",
    "    else:\n",
    "      ptr2 = ptr2 + 1\n",
    "\n",
    "  return ans, comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def not_t1(posting1):\n",
    "    global docIDs\n",
    "    ans = [] # to store all the docIDs except that are their in postings1\n",
    "\n",
    "    for i in docIDs:\n",
    "        if i in posting1:\n",
    "            continue\n",
    "        else:\n",
    "            ans.append(i)\n",
    "    return ans\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def t1_and_not_t2(posting1, posting2):\n",
    "#     # if the first posting is empty then the intersection will also be an empty list\n",
    "#     if len(posting1) == 0: \n",
    "#         return [], 0\n",
    "\n",
    "#     if len(posting2) == 0:\n",
    "#         return posting1, len(posting1)\n",
    "    \n",
    "#     # perform not query for posting2\n",
    "#     not_posting2 = not_t1(posting2)\n",
    "\n",
    "#     # now perform the and operation for posting1 and not_posting2\n",
    "#     ans, comparisons = t1_and_t2(posting1, not_posting2)\n",
    "#     return ans, comparisons\n",
    "    \n",
    "def t1_and_not_t2(posting1, posting2):\n",
    "    ptr1 = 0 #pointer that iterates over posting 1\n",
    "    ptr2 = 0 #pointer that iterates over posting 2\n",
    "\n",
    "    comparisons = 0 #intialize number of comparison as 0\n",
    "    ans = []\n",
    "\n",
    "    while ptr1 < len(posting1) and ptr2 < len(posting2):\n",
    "        comparisons += 1\n",
    "\n",
    "        if posting1[ptr1] == posting2[ptr2]: \n",
    "            ptr1+=1\n",
    "            ptr2+=1\n",
    "            continue\n",
    "        elif posting1[ptr1] < posting2[ptr2]:\n",
    "            ans.append( posting1[ptr1] )\n",
    "            ptr1+=1\n",
    "\n",
    "        else:\n",
    "            ptr2+=1\n",
    "\n",
    "    while ptr1 < len(posting1):\n",
    "        ans.append(posting1[ptr1])\n",
    "        ptr1+=1\n",
    "\n",
    "    return ans, comparisons\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1_or_t2(posting1, posting2):\n",
    "\n",
    "    #if any of the posting list is empty we will return the other list.\n",
    "    if len(posting1) == 0 :\n",
    "        return posting2, 0\n",
    "    if len(posting2) == 0:\n",
    "        return posting1, 0\n",
    "        \n",
    "    ptr1 = 0 #pointer that iterates over posting 1\n",
    "    ptr2 = 0 #pointer that iterates over posting 2\n",
    "\n",
    "    comparisons = 0 #intialize number of comparison as 0\n",
    "    ans = []\n",
    "\n",
    "    while ptr1 < len(posting1) and ptr2 < len(posting2):\n",
    "        comparisons+=1\n",
    "        if posting1[ptr1] < posting2[ptr2]:\n",
    "            ans.append(posting1[ptr1]) \n",
    "            ptr1+=1\n",
    "        elif posting2[ptr2] < posting1[ptr1]  :\n",
    "            ans.append(posting2[ptr2])\n",
    "            ptr2+=1\n",
    "        else:\n",
    "            ans.append(posting2[ptr2])\n",
    "            ptr1+=1\n",
    "            ptr2+=1\n",
    "\n",
    "    while(ptr1 < len(posting1)):\n",
    "        ans.append( posting1[ptr1] )\n",
    "        ptr1+=1\n",
    "    \n",
    "    while(ptr2 < len(posting2)):\n",
    "        ans.append( posting2[ptr2] )\n",
    "        ptr2+=1\n",
    "    \n",
    "    return ans, comparisons\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t1_or_not_t2(posting1, posting2):\n",
    "    # here we need to take the not of posting2 and then do an or with posting 1\n",
    "\n",
    "    if len(posting1) == 0: #if the first posting list is empty we will return the not of the other list.\n",
    "        return not_t1(posting2)\n",
    "    \n",
    "    not_posting2 = not_t1(posting2)\n",
    "\n",
    "    ans, comparisons = t1_or_t2(posting1, not_posting2)\n",
    "    return ans, comparisons\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1 = [1,2,3,4]\n",
    "# l2 = [2,3,7,9,19]\n",
    "# print(t1_or_not_t2(l1,l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd95411cf6954ceeae1c521b31885af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inv_idx_freq  = defaultdict(int) # initializing the doc Frequency dictionary as a default dict which return 0 whenver a key does not exists.\n",
    "inv_idx_postings  = defaultdict(list) # intializing the postings dictionary to return an empty list whenever it is invoked for a key that does not exits.\n",
    "sample = 5\n",
    "docIDs = []\n",
    "folder_path = 'Q1_2_output'\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            contents = file.read()\n",
    "            docID = int(filename[-4:])\n",
    "            docIDs.append(docID)\n",
    "            # print(docID)\n",
    "            # set_of_tokens = set(contents.strip('][').split(','))\n",
    "            set_of_tokens = set(ast.literal_eval(contents))\n",
    "            helper(inv_idx_freq, inv_idx_postings, set_of_tokens, docID)\n",
    "            # print(f'{filename}: {contents}')\n",
    "            # print(set_of_tokens)\n",
    "            # sample -= 1\n",
    "            # if (sample == 0):\n",
    "            #     break\n",
    "\n",
    "\n",
    "#sort the index in alphabetical order wrt terms\n",
    "inv_idx_postings = dict(sorted(inv_idx_postings.items()))\n",
    "inv_idx_freq = dict(sorted(inv_idx_freq.items()))\n",
    "\n",
    "for key in inv_idx_postings:\n",
    "    inv_idx_postings[key].sort() #sort the indivdual posting lists correponging to each term in the index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(inv_idx_postings, open('inv_idx_postings.pkl', 'wb'))\n",
    "pickle.dump(inv_idx_freq, open('inv_idx_freq.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_idx_postings = pickle.load(open(\"inv_idx_postings.pkl\", 'rb'))\n",
    "inv_idx_freq = pickle.load(open(\"inv_idx_freq.pkl\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inv_idx_postings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n"
     ]
    }
   ],
   "source": [
    "print(inv_idx_freq['surface'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punc(token):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return token.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_query(query):\n",
    "    content1 = query.lower()\n",
    "    content1 = contractions.fix(content1)\n",
    "    tokens = word_tokenize(content1)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens1 = [token for token in tokens if token not in stop_words]\n",
    "    tokens2 = list(map(remove_punc, tokens1))\n",
    "    tokens3 = [token for token in tokens2 if token.strip()]\n",
    "    return tokens3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['experimental', 'fly', 'design']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_query(\"experimental fly design\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['investigation', 'experimental', 'wing']\n",
      "['AND', 'AND']\n",
      "[1, 19, 29, 30, 74, 78, 84, 170, 173, 176, 179, 184, 187, 188, 189, 197, 202, 207, 212, 216, 222, 225, 245, 251, 294, 339, 372, 423, 427, 442, 462, 497, 505, 522, 549, 552, 567, 569, 634, 635, 636, 662, 689, 694, 712, 713, 739, 766, 772, 801, 816, 836, 844, 858, 887, 907, 927, 932, 946, 959, 986, 996, 997, 1019, 1039, 1062, 1066, 1074, 1075, 1078, 1083, 1092, 1097, 1098, 1156, 1159, 1161, 1205, 1213, 1220, 1225, 1227, 1230, 1231, 1337, 1338, 1341, 1352, 1364] 441\n",
      "[1, 30, 78, 189, 202, 222, 225, 442, 497, 636, 694, 712, 1062, 1074, 1075, 1092, 1337, 1338, 1341] 679\n"
     ]
    }
   ],
   "source": [
    "queries=int(input())\n",
    "while(queries>0):\n",
    "    query=input()\n",
    "    query=preprocess_query(query)\n",
    "    print(query)\n",
    "    operations=input().split(',')\n",
    "    print(operations)\n",
    "    q_ptr=1\n",
    "    o_ptr=0\n",
    "    answer=inv_idx_postings[query[0]]\n",
    "    comparisions=0\n",
    "    while(q_ptr<len(query) and o_ptr<len(operations)):\n",
    "        T2=query[q_ptr]\n",
    "        operation=operations[o_ptr]\n",
    "        if operation==\"AND\":\n",
    "            answer,temp=t1_and_t2(answer, inv_idx_postings[T2])\n",
    "            comparisions+=temp\n",
    "        elif operation==\"OR\":\n",
    "            answer,temp=t1_or_t2(answer, inv_idx_postings[T2])\n",
    "            comparisions+=temp\n",
    "        elif operation==\"AND NOT\":\n",
    "            answer,temp=t1_and_not_t2(answer, inv_idx_postings[T2])\n",
    "            comparisions+=temp\n",
    "        elif operation==\"OR NOT\":\n",
    "            answer,temp=t1_or_not_t2(answer, inv_idx_postings[T2])\n",
    "            comparisions+=temp\n",
    "        q_ptr+=1\n",
    "        o_ptr+=1\n",
    "        print(answer, comparisions)\n",
    "    queries-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12,\n",
       " 27,\n",
       " 36,\n",
       " 102,\n",
       " 124,\n",
       " 135,\n",
       " 172,\n",
       " 173,\n",
       " 198,\n",
       " 212,\n",
       " 213,\n",
       " 215,\n",
       " 221,\n",
       " 235,\n",
       " 239,\n",
       " 246,\n",
       " 249,\n",
       " 256,\n",
       " 270,\n",
       " 277,\n",
       " 301,\n",
       " 312,\n",
       " 328,\n",
       " 341,\n",
       " 367,\n",
       " 368,\n",
       " 415,\n",
       " 416,\n",
       " 419,\n",
       " 426,\n",
       " 429,\n",
       " 503,\n",
       " 519,\n",
       " 529,\n",
       " 535,\n",
       " 543,\n",
       " 554,\n",
       " 581,\n",
       " 592,\n",
       " 596,\n",
       " 602,\n",
       " 603,\n",
       " 612,\n",
       " 628,\n",
       " 640,\n",
       " 649,\n",
       " 650,\n",
       " 658,\n",
       " 674,\n",
       " 683,\n",
       " 696,\n",
       " 712,\n",
       " 724,\n",
       " 729,\n",
       " 733,\n",
       " 746,\n",
       " 753,\n",
       " 758,\n",
       " 762,\n",
       " 772,\n",
       " 797,\n",
       " 798,\n",
       " 833,\n",
       " 834,\n",
       " 836,\n",
       " 839,\n",
       " 868,\n",
       " 870,\n",
       " 876,\n",
       " 880,\n",
       " 883,\n",
       " 893,\n",
       " 896,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 921,\n",
       " 924,\n",
       " 928,\n",
       " 935,\n",
       " 945,\n",
       " 948,\n",
       " 964,\n",
       " 981,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 1012,\n",
       " 1015,\n",
       " 1018,\n",
       " 1033,\n",
       " 1039,\n",
       " 1051,\n",
       " 1059,\n",
       " 1069,\n",
       " 1093,\n",
       " 1104,\n",
       " 1117,\n",
       " 1124,\n",
       " 1131,\n",
       " 1136,\n",
       " 1176,\n",
       " 1188,\n",
       " 1207,\n",
       " 1246,\n",
       " 1279,\n",
       " 1292,\n",
       " 1293,\n",
       " 1310,\n",
       " 1342,\n",
       " 1351,\n",
       " 1353,\n",
       " 1360,\n",
       " 1362,\n",
       " 1380,\n",
       " 1387,\n",
       " 1397,\n",
       " 1399]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_idx_postings['design']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9509631f6d892f4e9e996ac093b0c5f431d646c0c87d4a83f341ba5e921b848"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
